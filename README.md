# Warsztaty Badawcze - Grupa: Osobowość w sztucznej inteligencji: czy modele językowe potrzebują psychologii?

Zajęcia mają miejsce we wtorki **14.15-15.45**.

## Rozkład zajęć 
- 2025-02-25 - Prezentacja tematyki projektów
- 2025-03-04 - Zajęcie organizacyjne + [wprowadzenie do LLM-ów ](https://github.com/WiktoriaMK/PW_warsztaty_badawcze/blob/main/prezentacje/WB%20-%20LLMs%20wst%C4%99p.pdf)
- 2025-03-11 - Wprowadzenie teoretyczne do psychologii osobowości + omówienie artykułów 
- 2025-03-18 - Omówienie i dyskusja literatury - grupa 1,2,3 
- 2025-03-25 - Omówienie i dyskusja literatury - grupa 4,5
- 2025-04-01 - Dyskusja projektów 
- 2025-04-08 - Konsultacje projektów indywidualnych (on-line)
- 2025-04-15 - Przedstawienie postępów projektów  -> **Kamień milowy nr 1**
- 2025-04-29 - Konsultacje projektów indywidualnych (on-line) 
- 2025-05-06 - Konsultacje projektów indywidualnych (on-line)
- 2025-05-20 - Przedstawienie postępów projektów -> **Kamień milowy nr 2**
- 2025-05-27 - Konsultacje projektów indywidualnych
- 2025-06-03 - **Prezentacje** finalnych projektów
- 2025-06-10 - **Prezentacje** finalnych projektów

## Narzędzia
a) Promptowanie 
- https://www.together.ai/ 
- https://ollama.com/
- https://cloud.google.com/model-garden?hl=en 

## Ciekawe repozytoria
-https://github.com/kasperjunge/LLM-Guide 

## Prezentacje literatury

| lp | Tytuł artykułu | Grupa | Data prezentacji |
|----|--------------|-----------------|-----------------|
| 1  | [LLM Agents in Interaction: Measuring Personality Consistency and Linguistic Alignment in Interacting Populations of Large Language Models.](https://arxiv.org/abs/2402.02896 ) |  |  |
| 2  | [Self-assessment tests are unreliable measures of llm personality.](https://aclanthology.org/2024.blackboxnlp-1.20/) | Gimzicka, Kukla, Skwarek  | 25.03.2025 r. |
| 3  | [Do llms have distinct and consistent personality? TRAIT: Personality testset designed for llms with psychometrics.](https://arxiv.org/abs/2406.14703) |  |  |
| 4  | [The Dark Patterns of Personalized Persuasion in Large Language Models: Exposing Persuasive Linguistic Features for Big Five Personality Traits in LLMs Responses.](https://arxiv.org/abs/2411.06008) |  |  |
| 5  | [Limited Ability of LLMs to Simulate Human Psychological Behaviours: a Psychometric Analysis.](https://arxiv.org/abs/2405.07248) | Florek, Sobociński, Pozorski | 18.03.2025 |
| 6  | [Personality traits in large language models.](https://arxiv.org/abs/2307.00184) |  |  |
| 7  | [Resistance Against Manipulative AI: key factors and possible actions.](https://arxiv.org/abs/2404.14230) |  |  |
| 8  | [Can LLM "Self-report"?: Evaluating the Validity of Self-report Scales in Measuring Personality Design in LLM-based Chatbots.](https://arxiv.org/abs/2412.00207) |  |  |
| 9  | [The better angels of machine personality: How personality relates to llm safety.](https://arxiv.org/abs/2407.12344) |  |  |

UWAGA: Trzy grupy powinny się zgłosić do prezentacji na 18 marca i dwie grupy na 25 marca.

### Artykuły do wyboru

| lp | Autorzy | Tytuł | Krótki opis |
|----|-------|-------|---------------|
| 1 |Frisch, I., & Giulianelli, M. (2024) | [LLM Agents in Interaction: Measuring Personality Consistency and Linguistic Alignment in Interacting Populations of Large Language Models.](https://arxiv.org/abs/2402.02896 )| Artykuł analizuje użycie języka w kontekście interakcji agentów LLM, mierząc spójnośćich osobowości. Bada, jak cechy osobowości wpływają na użycie języka w warunkach interaktywnych i nieinteraktywnych, wykorzystując do analiz kategorie LIWC (Linguistic Inquiry and Word Count). |
| 2 | Gupta, A., Song, X., & Anumanchipalli, G. (2024, November) | [Self-assessment tests are unreliable measures of llm personality. In Proceedings of the 7th BlackboxNLP Workshop: Analyzing and Interpreting Neural Networks for NLP (pp. 301-314)]( https://aclanthology.org/2024.blackboxnlp-1.20/) |Artykuł ten podważa wiarygodność testów samooceny w pomiarze osobowości LLM. Wykazuje, że wyniki testów w LLM nie są odporne na równoważne pytania i kolejność prezentowanych opcji. Badanie to analizuje wrażliwość na sformułowania pytań, porównując odpowiedzi modeli na trzy semantycznie równoważne pytania. |
| 3 | Lee, S., Lim, S., Han, S., Oh, G., Chae, H., Chung, J., ... & Yu, Y. (2024) | [Do llms have distinct and consistent personality? TRAIT: Personality testset designed for llms with psychometrics.](https://arxiv.org/abs/2406.14703) | Artykuł naukowy przedstawia TRAIT, nowy test psychometryczny stworzony do oceny osobowości dużych modeli językowych (LLM) w oparciu o popularne kwestionariusze ludzkie |
| 4 | Mieleszczenko-Kowszewicz, W., Płudowski, D., Kołodziejczyk, F., Świstak, J., Sienkiewicz, J., & Biecek, P. (2024) | [The Dark Patterns of Personalized Persuasion in Large Language Models: Exposing Persuasive Linguistic Features for Big Five Personality Traits in LLMs Responses.](https://arxiv.org/abs/2411.06008) | Artykuł bada, w jaki sposób LLM dostosowują swoje odpowiedzi w oparciu o osobowość użytkownika w zadaniu perswazji. Analizuje wzorce językowe używane przez modele w zależności od cech osobowości odbiorcy. W eksperymencie użyto różnorodnego zestawu 19 LLM i analizowano, jak modele te reagują na zmienne w zapytaniach perswazyjnych. |
| 5 | Petrov, N. B., Serapio-García, G., & Rentfrow, J. (2024) | [Limited Ability of LLMs to Simulate Human Psychological Behaviours: a Psychometric Analysis.](https://arxiv.org/abs/2405.07248) | Artykuł ten bada, czy duże modele językowe (LLM) są w stanie symulować ludzkie zachowania i osobowości. Wykorzystuje rygorystyczne metodologie psychometryczne do oceny, czy LLM mogą naśladować latentne konstrukty psychologiczne, które wpływają na zachowania w różnych zadaniach. Badacze użyli szablonu do zapytań, który zawierał instrukcję dotyczącą osobowości, opis persony, instrukcję testową, treść pytań. |
| 6 | Safdari, M., Serapio-García, G., Crepy, C., Fitz, S., Romero, P., Sun, L., Fitz, S., Romero, P., Abdulhai, M., Faust, A. & Matarić, M. (2023) | [Personality traits in large language models.](https://arxiv.org/abs/2307.00184) | Artykuł bada pomiar i kształtowanie osobowości w dużych modelach językowych (LLM). Sprawdza, czy LLM-y wiarygodnie symulują ludzką osobowość i czy można ją kształtować za pomocą strukturyzowanych podpowiedzi i testów osobowości. |
| 7 | Wilczyński, P., Mieleszczenko-Kowszewicz, W. & Biecek, P. (2024) | [Resistance Against Manipulative AI: key factors and possible actions. In: 27th European Conference on Artificial Intelligence. IOS Press.](https://arxiv.org/abs/2404.14230) | Artykuł "Resistance Against Manipulative AI" dotyczy problemu manipulacji ludźmi przez duże modele językowe (LLM). |
| 8 | Zou, H., Wang, P., Yan, Z., Sun, T., & Xiao, Z. (2024) | [Can LLM" Self-report"?: Evaluating the Validity of Self-report Scales in Measuring Personality Design in LLM-based Chatbots.](https://arxiv.org/abs/2412.00207) | Artykuł ten dotyczy badania, w jaki sposób można ocenić osobowość chatbotów z perspektywy człowieka, rekrutując uczestników do interakcji z chatbotami i wypełniania kwestionariuszy oceny osobowości oraz kwestionariuszy doświadczeń użytkownika. |
| 9 | Zhang, J., Liu, D., Qian, C., Gan, Z., Liu, Y., Qiao, Y., & Shao, J. (2024) | [The better angels of machine personality: How personality relates to llm safety.](https://arxiv.org/abs/2407.12344) |Artykuł analizuje, jak można kontrolować i edytować cechy osobowości w LLM, używając techniki wektorów sterujących. Bada, jak różne ustawienia, takie jak język i kolejność opcji, wpływają na ocenę MBTI (Myers-Briggs Type Indicator) dla LLM. W badaniu wykorzystano chińskie i angielskie wersje kwestionariusza MBTI-M, aby ocenić wyniki osobowości LLM w różnych kontekstach kulturowych. |

## Punktacja
max. 60 punktów:

1. 2 prace domowe : 4 pkt każda, łącznie max. 8 punktów 
2. Prezentacja literatury : 12 pkt 
3. Projekt :
   - Kamień milowy 1 -> 10 pkt
   - Kamień milowy 2 -> 20 pkt
   - Prezentacja projektu -> 10 pkt
  
Dodatkowe punkty mogą zostać przyznane za aktywność.
   
## Komunikacja

Slack, USOS

## Projekty

Opis dokładnych deliverables na poszczególne kamienie milowe - TBD.

