# Warsztaty Badawcze - Grupa: Osobowość w sztucznej inteligencji: czy modele językowe potrzebują psychologii?

Zajęcia mają miejsce we wtorki **14.15-15.45**.

## Rozkład zajęć 
- 2025-02-25 - Prezentacja tematyki projektów
- 2025-03-04 - Zajęcie organizacyjne + [wprowadzenie do LLM-ów ](https://github.com/WiktoriaMK/PW_warsztaty_badawcze/blob/main/prezentacje/WB%20-%20LLMs%20wst%C4%99p.pdf)
- 2025-03-11 - Wprowadzenie teoretyczne do psychologii osobowości + omówienie artykułów 
- 2025-03-18 - Omówienie i dyskusja literatury - grupa 1,2,3 
- 2025-03-25 - Omówienie i dyskusja literatury - grupa 4,5
- 2025-04-01 - Dyskusja projektów 
- 2025-04-08 - Konsultacje projektów indywidualnych (on-line)
- 2025-04-15 - Konsultacje projektów indywidualnych (stacjonarnie)  [UPDATE]
- 2025-04-29 - Przedstawienie postępów projektów  -> **Kamień milowy nr 1** [UPDATE]
- 2025-05-06 - Konsultacje projektów indywidualnych (on-line)
- 2025-05-13 - **Obecność obowiązkowa** Prace przygotowujące do KM2 + opcjonalne konsultacje
- 2025-05-20 - Przedstawienie postępów projektów -> **Kamień milowy nr 2** (stacjonarnie)
- 2025-05-27 - Konsultacje projektów indywidualnych (stacjonarnie)
- 2025-06-03 - **Prezentacje** finalnych projektów (stacjonarnie)
- 2025-06-10 - **Prezentacje** finalnych projektów (stacjonarnie)

## Narzędzia
a) Promptowanie 
- https://www.together.ai/ 
- https://ollama.com/
- https://cloud.google.com/model-garden?hl=en 

## Ciekawe repozytoria
-https://github.com/kasperjunge/LLM-Guide 

## Prezentacje literatury

| lp | Tytuł artykułu | Grupa | Data prezentacji |
|----|--------------|-----------------|-----------------|
| 1  | [LLM Agents in Interaction: Measuring Personality Consistency and Linguistic Alignment in Interacting Populations of Large Language Models.](https://arxiv.org/abs/2402.02896 ) | Warno, Baraniak | 25.03.2025 |
| 2  | [Self-assessment tests are unreliable measures of llm personality.](https://aclanthology.org/2024.blackboxnlp-1.20/) | Gimzicka, Kukla, Skwarek  | 25.03.2025 r. |
| 4  | [The Dark Patterns of Personalized Persuasion in Large Language Models: Exposing Persuasive Linguistic Features for Big Five Personality Traits in LLMs Responses.](https://arxiv.org/abs/2411.06008) | Adamczyk, Cwalina, Iwaniuk | 18.03.2025 |
| 5  | [Limited Ability of LLMs to Simulate Human Psychological Behaviours: a Psychometric Analysis.](https://arxiv.org/abs/2405.07248) | Florek, Sobociński, Pozorski | 18.03.2025 |
| 10 | [Evaluating large language models in theory of mind tasks](https://arxiv.org/pdf/2302.02083) | Opala, Pytel, Rogalska | 25.03.2025 r. |

UWAGA: Trzy grupy powinny się zgłosić do prezentacji na 18 marca i dwie grupy na 25 marca.

## Punktacja
max. 60 punktów:

1. 2 prace domowe : 4 pkt każda, łącznie max. 8 punktów 
2. Prezentacja literatury : 12 pkt 
3. Projekt :
   - Kamień milowy 1 -> 10 pkt
   - Kamień milowy 2 -> 20 pkt
   - Prezentacja projektu -> 10 pkt
  
Dodatkowe punkty mogą zostać przyznane za aktywność.

## Szczegóły dotyczące punktacji i wymagań na poszczególne deliverables
### Omówienie literatury (12 pkt)
- Ogólne streszczenie artykułu - 2 pkt
- Zastosowane metody - 2 pkt
- Przeprowadzone eksperymenty - 2  pkt
- Wyniki i wnioski - 2 pkt
- Limitations/ future works (na tej części powinien bazować poźniejszy plan badawczy projektu) - 3 pkt
- O autorach artykułu - 1 pkt
  
Czas na prezentację literatury: 20min prezentacja + 5min pytania
### Punktacja za KM1 (10 pkt)
- Przygotowanie opracowanego planu badawczego: 1-2 strony A4  (w sumie 8 pkt, podzielone jak poniżej)
   - Pytanie badawcze - 2 pkt
   - Jaki model/ jakie modele zostaną wykorzystane - 1.5 pkt
   - Jakie prompty zostaną wykorzystane - 1.5 pkt
   - Jakie koncepcje psychologiczne zostaną wykorzystane - 2 pkt
   - Podział pracy między członków zespołu - 1 pkt
- Założenie repozytorium zespołu i udostępnienie prowadzącym (niezbędne do zaliczenia KM1) - repozytoria prywatne
- Zaprezentowanie planu badawczego podczas zajęć 29.04: 12 min na prezentację + 3 min na pytania (zapisy poniżej) -> 2 pkt

## Prezentacje KM1 29.04.2025

| lp | Tytuł artykułu | Grupa | Godzina prezentacji |
|----|--------------|-----------------|-----------------|
| 1  | [LLM Agents in Interaction: Measuring Personality Consistency and Linguistic Alignment in Interacting Populations of Large Language Models.](https://arxiv.org/abs/2402.02896 ) | Warno, Baraniak | 14.20-14.35 |
| 2  | Self-assessment tests are unreliable measures of llm personality | Gimzicka, Kukla, Skwarek | 14.35-14.50 |
| 3  | The Dark Patterns of Personalized Persuasion in Large Language Models | Adamczyk, Cwalina, Iwaniuk | 14.50-15.05 |
| 4  | [Evaluating large language models in theory of mind tasks](https://arxiv.org/pdf/2302.02083) | Rogalska, Opala, Pytel | 15.05-15.20 |
| 5  | [Limited Ability of LLMs to Simulate Human Psychological Behaviours: a Psychometric Analysis.](https://arxiv.org/abs/2405.07248) | Florek, Pozorski, Sobociński | 15.20-15.35 |

### Punktacja za KM2 (20 pkt)
- Przygotowanie podsumowania prac: 4-6 stron A4 dokumentu lub Jupyter Notebook zawierającego (w sumie 13 pkt, podzielone jak poniżej):
   - Opis co zostało wykonane w ramach projektu (cel badawczy, wykorzystane modele, cele i krótkie opisy eksperymentów) -> 3 pkt
   - Rezultaty osiągnięte podczas eksperymentów -> 3 pkt
   - Dyskusja: co wyszło, co nie, jakie problemy pojawiły się podczas pracy nad projektem -> 3 pkt
   - Future works, potencjalne zastosowanie w biznesie, plan pracy na ostatnie kilka tygodni pracy nad projektem, podział pracy między członków zespołu -> 1pkt
   - Uzasadnienie merytoryczne dlaczego taki cel badawczy został wybrany, dlaczego takie a nie inne metody i narzędzia zostały użyte, a eksperymenty przeprowadzone -> 3 pkt
- Zaprezentowanie dotychczasowych efektów pracy podczas zajęć 20.05: 12 min na prezentację + 3 min na pytania (zapisy poniżej) -> 2 pkt
- Udostępnienie kodu na repozytorium zespołu odzwierciedlającego opisywane eksperymenty i ich wyniki -> 5 pkt
   - Wszystkie materiały dostarczone na repozytorium powinny pozwalać na bezproblemowe uruchomienie przestawionych eksperymentów oraz zreprodukowanie wyników

 ## Prezentacje KM2 20.05.2025

| lp | Tytuł artykułu | Grupa | Godzina prezentacji |
|----|--------------|-----------------|-----------------|
| 1  | ... | ... | 14.20-14.35 |
| 2  | [Evaluating large language models in theory of mind tasks](https://arxiv.org/pdf/2302.02083)| Rogalska, Opala, Pytel | 14.35-14.50 |
| 3  | Self-assessment tests are unreliable measures of llm personality | Gimzicka, Kukla, Skwarek | 14.50-15.05 |
| 4  | ... | ... | 15.05-15.20 |
| 5  | [Limited Ability of LLMs to Simulate Human Psychological Behaviours: a Psychometric Analysis.](https://arxiv.org/abs/2405.07248) | Florek, Pozorski, Sobociński | 15.20-15.35 |
  
### Punktacja za prezentację (10 pkt)
- Wprowadzenie teoretyczne, cel, pytanie badawcze - 2 pkt
- Zastosowane metody - 2 pkt
- Opis eksperymentów - 1 pkt
- Wyniki i wnioski - 2 pkt
- Future works, potencjalne zastosowanie w biznesie - 2 pkt
- Czytelność slajdów, poprawność wizualizacji - 1 pkt
  
## Komunikacja

Slack, USOS

### Artykuły wybrane - podsumowanie

| lp | Autorzy | Tytuł | Krótki opis |
|----|-------|-------|---------------|
| 1 |Frisch, I., & Giulianelli, M. (2024) | [LLM Agents in Interaction: Measuring Personality Consistency and Linguistic Alignment in Interacting Populations of Large Language Models.](https://arxiv.org/abs/2402.02896 )| Artykuł analizuje użycie języka w kontekście interakcji agentów LLM, mierząc spójnośćich osobowości. Bada, jak cechy osobowości wpływają na użycie języka w warunkach interaktywnych i nieinteraktywnych, wykorzystując do analiz kategorie LIWC (Linguistic Inquiry and Word Count). |
| 2 | Gupta, A., Song, X., & Anumanchipalli, G. (2024, November) | [Self-assessment tests are unreliable measures of llm personality. In Proceedings of the 7th BlackboxNLP Workshop: Analyzing and Interpreting Neural Networks for NLP (pp. 301-314)]( https://aclanthology.org/2024.blackboxnlp-1.20/) |Artykuł ten podważa wiarygodność testów samooceny w pomiarze osobowości LLM. Wykazuje, że wyniki testów w LLM nie są odporne na równoważne pytania i kolejność prezentowanych opcji. Badanie to analizuje wrażliwość na sformułowania pytań, porównując odpowiedzi modeli na trzy semantycznie równoważne pytania. |
| 4 | Mieleszczenko-Kowszewicz, W., Płudowski, D., Kołodziejczyk, F., Świstak, J., Sienkiewicz, J., & Biecek, P. (2024) | [The Dark Patterns of Personalized Persuasion in Large Language Models: Exposing Persuasive Linguistic Features for Big Five Personality Traits in LLMs Responses.](https://arxiv.org/abs/2411.06008) | Artykuł bada, w jaki sposób LLM dostosowują swoje odpowiedzi w oparciu o osobowość użytkownika w zadaniu perswazji. Analizuje wzorce językowe używane przez modele w zależności od cech osobowości odbiorcy. W eksperymencie użyto różnorodnego zestawu 19 LLM i analizowano, jak modele te reagują na zmienne w zapytaniach perswazyjnych. |
| 5 | Petrov, N. B., Serapio-García, G., & Rentfrow, J. (2024) | [Limited Ability of LLMs to Simulate Human Psychological Behaviours: a Psychometric Analysis.](https://arxiv.org/abs/2405.07248) | Artykuł ten bada, czy duże modele językowe (LLM) są w stanie symulować ludzkie zachowania i osobowości. Wykorzystuje rygorystyczne metodologie psychometryczne do oceny, czy LLM mogą naśladować latentne konstrukty psychologiczne, które wpływają na zachowania w różnych zadaniach. Badacze użyli szablonu do zapytań, który zawierał instrukcję dotyczącą osobowości, opis persony, instrukcję testową, treść pytań. |
| 10 | Kosinski, M., (2024) | [Evaluating large language models in theory of mind tasks](https://arxiv.org/pdf/2302.02083) | Badanie teorii umysłu różnych LLMów | 

